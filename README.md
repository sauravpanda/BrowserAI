# BrowserAI ğŸš€

BrowserAI: Run LLMs in the Browser - Simple, Fast, and Open Source!

## Why BrowserAI?

- ğŸ”’ **Privacy First**: All processing happens locally - your data never leaves the browser
- ğŸ’° **Cost Effective**: No server costs or complex infrastructure needed
- ğŸŒ **Offline Capable**: Models work offline after initial download
- ğŸš€ **Blazing Fast**: WebGPU acceleration for near-native performance
- ğŸ¯ **Developer Friendly**: Simple API, multiple engine support, ready-to-use models

## ğŸ¯ Perfect For

- Web developers building AI-powered applications
- Companies needing privacy-conscious AI solutions
- Researchers experimenting with browser-based AI
- Hobbyists exploring AI without infrastructure overhead

## âœ¨ Features

- ğŸ¯ Run AI models directly in the browser - no server required!
- âš¡ WebGPU acceleration for blazing fast inference
- ğŸ”„ Seamless switching between MLC and Transformers engines
- ğŸ“¦ Pre-configured popular models ready to use
- ğŸ› ï¸ Easy-to-use API for text generation and more

## ğŸš€ Quick Start
```
bash
npm install @browserai/browserai
```

OR 
```
bash
yarn add @browserai/browserai
```

### Basic Usage

```javascript
import { BrowserAI } from '@browserai/browserai';

const browserAI = new BrowserAI();

browserAI.loadModel('llama-3.2-1b-instruct');

const response = await browserAI.generateText('Hello, how are you?');
console.log(response);
```


## ğŸ“š Examples

### Text Generation with Custom Parameters
```javascript
const ai = new BrowserAI();
await ai.loadModel('llama-3.2-1b-instruct', {
quantization: 'q4f16_1' // Optimize for size/speed
});
const response = await ai.generateText('Write a short poem about coding', {
temperature: 0.8,
maxTokens: 100
});
```

### Speech Recognition
```javascript
const ai = new BrowserAI();
await ai.loadModel('whisper-tiny-en');
const audioBlob = await ai.stopRecording();
const transcription = await ai.transcribeAudio(audioBlob);
```

### Text-to-Speech
```javascript
const ai = new BrowserAI();
const audioBuffer = await ai.textToSpeech('Hello, how are you today?');
// Play the audio...
```

## ğŸ”§ Supported Models

More models will be added soon. Request a model by creating an issue.

### MLC Models
- Llama-3.2-1b-Instruct
- SmolLM2-135M-Instruct
- SmolLM2-350M-Instruct

### Transformers Models
- Llama-3.2-1b-Instruct
- Whisper-tiny-en (Speech Recognition)
- SpeechT5-TTS (Text-to-Speech)

## ğŸ—ºï¸ Enhanced Roadmap

### Phase 1: Foundation
- ğŸ¯ Simplified model initialization
- ğŸ“Š Basic monitoring and metrics
- ğŸ” Simple RAG implementation
- ğŸ› ï¸ Developer tools integration

### Phase 2: Advanced Features
- ğŸ“š Enhanced RAG capabilities
  - Hybrid search
  - Auto-chunking
  - Source tracking
- ğŸ“Š Advanced observability
  - Performance dashboards
  - Memory profiling
  - Error tracking

### Phase 3: Enterprise Features
- ğŸ” Security features
- ğŸ“ˆ Advanced analytics
- ğŸ¤ Multi-model orchestration

## ğŸ¤ Contributing

We welcome contributions! Feel free to:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [MLC AI](https://mlc.ai/) for their incredible mode compilation library and support for webgpu runtime and xgrammar
- [Hugging Face](https://huggingface.co/) for their Transformers.js library
- All our contributors and supporters!

---

<p align="center">Made with â¤ï¸ for the AI community</p>